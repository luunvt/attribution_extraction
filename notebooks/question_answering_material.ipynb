{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VC87y3An4v6"
      },
      "source": [
        "# Question answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPXfh6EIn4v7"
      },
      "source": [
        "Question answering tasks return an answer given a question. If you've ever asked a virtual assistant like Alexa, Siri or Google what the weather is, then you've used a question answering model before. There are two common types of question answering tasks:\n",
        "\n",
        "- Extractive: extract the answer from the given context.\n",
        "- Abstractive: generate an answer from the context that correctly answers the question.\n",
        "\n",
        "This guide will show you how to:\n",
        "\n",
        "1. Finetune [DistilBERT](https://huggingface.co/distilbert-base-uncased) on the [SQuAD](https://huggingface.co/datasets/squad) dataset for extractive question answering.\n",
        "2. Use your finetuned model for inference.\n",
        "\n",
        "<Tip>\n",
        "The task illustrated in this tutorial is supported by the following model architectures:\n",
        "\n",
        "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
        "\n",
        "[ALBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/albert), [BART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bart), [BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bert), [BigBird](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/big_bird), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bigbird_pegasus), [BLOOM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bloom), [CamemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/camembert), [CANINE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/canine), [ConvBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/convbert), [Data2VecText](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/data2vec-text), [DeBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta), [DeBERTa-v2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta-v2), [DistilBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/distilbert), [ELECTRA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/electra), [ERNIE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie), [ErnieM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie_m), [FlauBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/flaubert), [FNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/fnet), [Funnel Transformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/funnel), [OpenAI GPT-2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt2), [GPT Neo](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neo), [GPT NeoX](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neox), [GPT-J](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gptj), [I-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ibert), [LayoutLMv2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv2), [LayoutLMv3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv3), [LED](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/led), [LiLT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/lilt), [Longformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/longformer), [LUKE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/luke), [LXMERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/lxmert), [MarkupLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/markuplm), [mBART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mbart), [MEGA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mega), [Megatron-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/megatron-bert), [MobileBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mobilebert), [MPNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mpnet), [MVP](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mvp), [Nezha](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nezha), [Nystr√∂mformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nystromformer), [OPT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/opt), [QDQBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/qdqbert), [Reformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/reformer), [RemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/rembert), [RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta), [RoBERTa-PreLayerNorm](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta-prelayernorm), [RoCBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roc_bert), [RoFormer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roformer), [Splinter](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/splinter), [SqueezeBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/squeezebert), [XLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm), [XLM-RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta), [XLM-RoBERTa-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta-xl), [XLNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlnet), [X-MOD](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xmod), [YOSO](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/yoso)\n",
        "\n",
        "\n",
        "<!--End of the generated tip-->\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Before you begin, make sure you have all the necessary libraries installed:\n",
        "\n",
        "```bash\n",
        "pip install transformers datasets evaluate\n",
        "```\n",
        "\n",
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbT_EQMDn4v8"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "import ast\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>sentence</th>\n",
              "      <th>locs</th>\n",
              "      <th>words</th>\n",
              "      <th>loc_prediction</th>\n",
              "      <th>word_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B08K86G2ZB</td>\n",
              "      <td>GRIPPY NON SLIP TEXTURE - Keeps you from slidi...</td>\n",
              "      <td>[[197, 202, 'MAT']]</td>\n",
              "      <td>['matte']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B08K86G2ZB</td>\n",
              "      <td>PVC-FREE - Made from a EVA Foam / TPE material...</td>\n",
              "      <td>[[34, 37, 'MAT'], [27, 31, 'MAT']]</td>\n",
              "      <td>['TPE', 'Foam']</td>\n",
              "      <td>[[27, 31, 'MAT'], [34, 37, 'MAT']]</td>\n",
              "      <td>['Foam', 'TPE']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B08K85C9PB</td>\n",
              "      <td>GRIPPY NON SLIP TEXTURE - Keeps you from slidi...</td>\n",
              "      <td>[[197, 202, 'MAT']]</td>\n",
              "      <td>['matte']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B08K85C9PB</td>\n",
              "      <td>PVC-FREE - Made from a EVA Foam / TPE material...</td>\n",
              "      <td>[[34, 37, 'MAT'], [27, 31, 'MAT']]</td>\n",
              "      <td>['TPE', 'Foam']</td>\n",
              "      <td>[[27, 31, 'MAT'], [34, 37, 'MAT']]</td>\n",
              "      <td>['Foam', 'TPE']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B09N7FJJGC</td>\n",
              "      <td>Durable Construction: Made of durable, high- q...</td>\n",
              "      <td>[[53, 58, 'MAT']]</td>\n",
              "      <td>['metal']</td>\n",
              "      <td>[[53, 58, 'MAT']]</td>\n",
              "      <td>['metal']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>DURABLE LEATHER MATERIAL. To provide extreme d...</td>\n",
              "      <td>[[8, 15, 'MAT'], [107, 114, 'MAT'], [161, 168,...</td>\n",
              "      <td>['LEATHER', 'Leather', 'leather']</td>\n",
              "      <td>[[8, 15, 'MAT'], [107, 114, 'MAT'], [161, 168,...</td>\n",
              "      <td>['LEATHER', 'Leather', 'leather']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>HIGH-QUALITY CONSTRUCTION. A heavy-duty latex ...</td>\n",
              "      <td>[[40, 45, 'MAT']]</td>\n",
              "      <td>['latex']</td>\n",
              "      <td>[[40, 45, 'MAT']]</td>\n",
              "      <td>['latex']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>GREAT EXERCISE ACTIVITY. Practicing with this ...</td>\n",
              "      <td>[[46, 53, 'MAT']]</td>\n",
              "      <td>['Leather']</td>\n",
              "      <td>[[46, 53, 'MAT']]</td>\n",
              "      <td>['Leather']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>B0928J3RKC</td>\n",
              "      <td>ü•äQUALITY ASSURANCE - Kids punching bag with gl...</td>\n",
              "      <td>[[92, 99, 'MAT']]</td>\n",
              "      <td>['leather']</td>\n",
              "      <td>[[92, 99, 'MAT']]</td>\n",
              "      <td>['leather']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>B083M9ZSQ3</td>\n",
              "      <td>üëä HEAVY DUTY COMPOSITION No matter how long yo...</td>\n",
              "      <td>[[28, 33, 'MAT']]</td>\n",
              "      <td>['matte']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>782 rows √ó 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           asin                                           sentence  \\\n",
              "0    B08K86G2ZB  GRIPPY NON SLIP TEXTURE - Keeps you from slidi...   \n",
              "1    B08K86G2ZB  PVC-FREE - Made from a EVA Foam / TPE material...   \n",
              "2    B08K85C9PB  GRIPPY NON SLIP TEXTURE - Keeps you from slidi...   \n",
              "3    B08K85C9PB  PVC-FREE - Made from a EVA Foam / TPE material...   \n",
              "4    B09N7FJJGC  Durable Construction: Made of durable, high- q...   \n",
              "..          ...                                                ...   \n",
              "777  B07PFD4B2C  DURABLE LEATHER MATERIAL. To provide extreme d...   \n",
              "778  B07PFD4B2C  HIGH-QUALITY CONSTRUCTION. A heavy-duty latex ...   \n",
              "779  B07PFD4B2C  GREAT EXERCISE ACTIVITY. Practicing with this ...   \n",
              "780  B0928J3RKC  ü•äQUALITY ASSURANCE - Kids punching bag with gl...   \n",
              "781  B083M9ZSQ3  üëä HEAVY DUTY COMPOSITION No matter how long yo...   \n",
              "\n",
              "                                                  locs  \\\n",
              "0                                  [[197, 202, 'MAT']]   \n",
              "1                   [[34, 37, 'MAT'], [27, 31, 'MAT']]   \n",
              "2                                  [[197, 202, 'MAT']]   \n",
              "3                   [[34, 37, 'MAT'], [27, 31, 'MAT']]   \n",
              "4                                    [[53, 58, 'MAT']]   \n",
              "..                                                 ...   \n",
              "777  [[8, 15, 'MAT'], [107, 114, 'MAT'], [161, 168,...   \n",
              "778                                  [[40, 45, 'MAT']]   \n",
              "779                                  [[46, 53, 'MAT']]   \n",
              "780                                  [[92, 99, 'MAT']]   \n",
              "781                                  [[28, 33, 'MAT']]   \n",
              "\n",
              "                                 words  \\\n",
              "0                            ['matte']   \n",
              "1                      ['TPE', 'Foam']   \n",
              "2                            ['matte']   \n",
              "3                      ['TPE', 'Foam']   \n",
              "4                            ['metal']   \n",
              "..                                 ...   \n",
              "777  ['LEATHER', 'Leather', 'leather']   \n",
              "778                          ['latex']   \n",
              "779                        ['Leather']   \n",
              "780                        ['leather']   \n",
              "781                          ['matte']   \n",
              "\n",
              "                                        loc_prediction  \\\n",
              "0                                                   []   \n",
              "1                   [[27, 31, 'MAT'], [34, 37, 'MAT']]   \n",
              "2                                                   []   \n",
              "3                   [[27, 31, 'MAT'], [34, 37, 'MAT']]   \n",
              "4                                    [[53, 58, 'MAT']]   \n",
              "..                                                 ...   \n",
              "777  [[8, 15, 'MAT'], [107, 114, 'MAT'], [161, 168,...   \n",
              "778                                  [[40, 45, 'MAT']]   \n",
              "779                                  [[46, 53, 'MAT']]   \n",
              "780                                  [[92, 99, 'MAT']]   \n",
              "781                                                 []   \n",
              "\n",
              "                       word_prediction  \n",
              "0                                   []  \n",
              "1                      ['Foam', 'TPE']  \n",
              "2                                   []  \n",
              "3                      ['Foam', 'TPE']  \n",
              "4                            ['metal']  \n",
              "..                                 ...  \n",
              "777  ['LEATHER', 'Leather', 'leather']  \n",
              "778                          ['latex']  \n",
              "779                        ['Leather']  \n",
              "780                        ['leather']  \n",
              "781                                 []  \n",
              "\n",
              "[782 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f_label_mat = pd.read_excel(\"/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/notebooks/label_1941_1981_2143.xlsx\")\n",
        "display(f_label_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_ans = []\n",
        "for index, row in f_label_mat.iterrows():\n",
        "    locs = ast.literal_eval(row['locs'])\n",
        "    words = ast.literal_eval(row['words'])\n",
        "    for i, word in enumerate(words):\n",
        "        ans = {\n",
        "            'text': [word],\n",
        "            'answer_start': [locs[i][0]]\n",
        "        }\n",
        "        list_ans.append(ans)\n",
        "        break\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B08K86G2ZB</td>\n",
              "      <td>GRIPPY NON SLIP TEXTURE - Keeps you from slidi...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['matte'], 'answer_start': [197]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B08K86G2ZB</td>\n",
              "      <td>PVC-FREE - Made from a EVA Foam / TPE material...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['TPE'], 'answer_start': [34]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B08K85C9PB</td>\n",
              "      <td>GRIPPY NON SLIP TEXTURE - Keeps you from slidi...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['matte'], 'answer_start': [197]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B08K85C9PB</td>\n",
              "      <td>PVC-FREE - Made from a EVA Foam / TPE material...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['TPE'], 'answer_start': [34]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B09N7FJJGC</td>\n",
              "      <td>Durable Construction: Made of durable, high- q...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['metal'], 'answer_start': [53]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>DURABLE LEATHER MATERIAL. To provide extreme d...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['LEATHER'], 'answer_start': [8]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>HIGH-QUALITY CONSTRUCTION. A heavy-duty latex ...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['latex'], 'answer_start': [40]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>B07PFD4B2C</td>\n",
              "      <td>GREAT EXERCISE ACTIVITY. Practicing with this ...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['Leather'], 'answer_start': [46]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>B0928J3RKC</td>\n",
              "      <td>ü•äQUALITY ASSURANCE - Kids punching bag with gl...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['leather'], 'answer_start': [92]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>B083M9ZSQ3</td>\n",
              "      <td>üëä HEAVY DUTY COMPOSITION No matter how long yo...</td>\n",
              "      <td>What materials is this product made of?</td>\n",
              "      <td>{'text': ['matte'], 'answer_start': [28]}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>782 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                            context  \\\n",
              "0    B08K86G2ZB  GRIPPY NON SLIP TEXTURE - Keeps you from slidi...   \n",
              "1    B08K86G2ZB  PVC-FREE - Made from a EVA Foam / TPE material...   \n",
              "2    B08K85C9PB  GRIPPY NON SLIP TEXTURE - Keeps you from slidi...   \n",
              "3    B08K85C9PB  PVC-FREE - Made from a EVA Foam / TPE material...   \n",
              "4    B09N7FJJGC  Durable Construction: Made of durable, high- q...   \n",
              "..          ...                                                ...   \n",
              "777  B07PFD4B2C  DURABLE LEATHER MATERIAL. To provide extreme d...   \n",
              "778  B07PFD4B2C  HIGH-QUALITY CONSTRUCTION. A heavy-duty latex ...   \n",
              "779  B07PFD4B2C  GREAT EXERCISE ACTIVITY. Practicing with this ...   \n",
              "780  B0928J3RKC  ü•äQUALITY ASSURANCE - Kids punching bag with gl...   \n",
              "781  B083M9ZSQ3  üëä HEAVY DUTY COMPOSITION No matter how long yo...   \n",
              "\n",
              "                                    question  \\\n",
              "0    What materials is this product made of?   \n",
              "1    What materials is this product made of?   \n",
              "2    What materials is this product made of?   \n",
              "3    What materials is this product made of?   \n",
              "4    What materials is this product made of?   \n",
              "..                                       ...   \n",
              "777  What materials is this product made of?   \n",
              "778  What materials is this product made of?   \n",
              "779  What materials is this product made of?   \n",
              "780  What materials is this product made of?   \n",
              "781  What materials is this product made of?   \n",
              "\n",
              "                                         answers  \n",
              "0     {'text': ['matte'], 'answer_start': [197]}  \n",
              "1        {'text': ['TPE'], 'answer_start': [34]}  \n",
              "2     {'text': ['matte'], 'answer_start': [197]}  \n",
              "3        {'text': ['TPE'], 'answer_start': [34]}  \n",
              "4      {'text': ['metal'], 'answer_start': [53]}  \n",
              "..                                           ...  \n",
              "777   {'text': ['LEATHER'], 'answer_start': [8]}  \n",
              "778    {'text': ['latex'], 'answer_start': [40]}  \n",
              "779  {'text': ['Leather'], 'answer_start': [46]}  \n",
              "780  {'text': ['leather'], 'answer_start': [92]}  \n",
              "781    {'text': ['matte'], 'answer_start': [28]}  \n",
              "\n",
              "[782 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_df = pd.DataFrame()\n",
        "new_df['id'] =  f_label_mat['asin']\n",
        "new_df['context'] = f_label_mat['sentence']\n",
        "new_df['question'] = [\"What materials is this product made of?\" for x in range(len(f_label_mat))]\n",
        "new_df['answers'] = pd.Series(list_ans)\n",
        "display(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "squad = Dataset.from_pandas(new_df)\n",
        "squad = squad.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q4h3L1Kn4v-"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umd4mBuTn4v-"
      },
      "source": [
        "The next step is to load a DistilBERT tokenizer to process the `question` and `context` fields:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4Yw15Tc0n4v-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3kqESG6n4v-"
      },
      "source": [
        "There are a few preprocessing steps particular to question answering tasks you should be aware of:\n",
        "\n",
        "1. Some examples in a dataset may have a very long `context` that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the `context` by setting `truncation=\"only_second\"`.\n",
        "2. Next, map the start and end positions of the answer to the original `context` by setting\n",
        "   `return_offset_mapping=True`.\n",
        "3. With the mapping in hand, now you can find the start and end tokens of the answer. Use the [sequence_ids](https://huggingface.co/docs/tokenizers/main/en/api/encoding#tokenizers.Encoding.sequence_ids) method to\n",
        "   find which part of the offset corresponds to the `question` and which corresponds to the `context`.\n",
        "\n",
        "Here is how you can create a function to truncate and map the start and end tokens of the `answer` to the `context`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "486BIu06n4v-"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eleIQFzn4v-"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use ü§ó Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once. Remove any columns you don't need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "XYZB5rSAn4v-"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3d698f9b1a14bffabb515177fe8be14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/625 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e10275b1f3184e6aabf72af33d7531aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVWISZdon4v-"
      },
      "source": [
        "Now create a batch of examples using [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator). Unlike other data collators in ü§ó Transformers, the [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) does not apply any additional preprocessing such as padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "f65f1obSn4v-"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDtMJDpon4v-"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJ4HVbdn4v-"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "You're ready to start training your model now! Load DistilBERT with [AutoModelForQuestionAnswering](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForQuestionAnswering):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sEKp2KHen4v-"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b283a0ce9244aa8bbf021c5c75963e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwOHLuGnn4v-"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model).\n",
        "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, and data collator.\n",
        "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZifDsnn2n4v-"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caaa83df16a946368c6b5e01a5cd2e88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2314469fc6c74992acd7a467e5b486de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.45357745885849, 'eval_runtime': 1.1334, 'eval_samples_per_second': 138.52, 'eval_steps_per_second': 8.823, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a9a122257bd4ae8be2dff283ecf1614",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3574216365814209, 'eval_runtime': 1.1278, 'eval_samples_per_second': 139.204, 'eval_steps_per_second': 8.867, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e3696d72349483bbe90c658f0673c38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.36656296253204346, 'eval_runtime': 1.1307, 'eval_samples_per_second': 138.85, 'eval_steps_per_second': 8.844, 'epoch': 3.0}\n",
            "{'train_runtime': 46.9633, 'train_samples_per_second': 39.925, 'train_steps_per_second': 2.555, 'train_loss': 0.2218625068664551, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.2218625068664551, metrics={'train_runtime': 46.9633, 'train_samples_per_second': 39.925, 'train_steps_per_second': 2.555, 'train_loss': 0.2218625068664551, 'epoch': 3.0})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./my_awesome_qa_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad[\"train\"],\n",
        "    eval_dataset=tokenized_squad[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PtIzSy_n4v_"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoZHQvJIn4v_"
      },
      "source": [
        "Evaluation for question answering requires a significant amount of postprocessing. To avoid taking up too much of your time, this guide skips the evaluation step. The [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) still calculates the evaluation loss during training so you're not completely in the dark about your model's performance.\n",
        "\n",
        "If have more time and you're interested in how to evaluate your model for question answering, take a look at the [Question answering](https://huggingface.co/course/chapter7/7?fw=pt#postprocessing) chapter from the ü§ó Hugging Face Course!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbMBT-bln4v_"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBBoCGlHn4v_"
      },
      "source": [
        "Great, now that you've finetuned a model, you can use it for inference!\n",
        "\n",
        "Come up with a question and some context you'd like the model to predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8XNNCC3Bn4v_"
      },
      "outputs": [],
      "source": [
        "question = \"What materials is this product made of?\"\n",
        "context = '''\n",
        "['Relax and take a load off in your garden or patio on this comfortable wooden sun lounger! You can spend a relaxing afternoon in your own outdoor space! It is perfect for a pool, balcony, garden, etc.', 'This outdoor sun lounger is made of solid acacia wood, making it sturdy and stable. The lounge bed features an ergonomically curved shape, allowing you to lie down and fully relax. This sunbed can be folded away when not in use. The cushion with head pillow adds extra comfort for you while lounging. Each cushion features six sets of ropes so that you can fix it on the sun lounger tightly.', 'This sun lounger offers you a comfortable outdoor relaxation experience. These outdoor loungers are perfect for your outdoor activities, such as soaking up the sun or relaxing after a swim. It is the ideal relaxation and vacation companion for you and your family to relax and enjoy near the pool, on the beach, in the garden, on the deck, etc.', 'Color of cushion: Red Material: Solid acacia wood with an oil finish Material of cushion: Fabric (100% polyester) Dimensions (unfolded): 72.4\" x 21.7\" x 25.2\" (L x W x H) Dimensions (folded): 36.2\" x 21.7\" x 7.9\" (L x W x H) Dimension of cushion: 73.2\" x 22.8\" x 1.2\" (L x W x T) Dimension of head cushion: 18.5\" x 11.8\" x 1.2\" (L x W x T) Assembly required: No Delivery contains: 1 x Sunlounger 1 x Cushion', 'We ship quickly, thirty days no reason after-sales is your best after-sales guarantee, you can rest assured that the purchase, if you have any questions, please contact us in a timely manner, we will see the first time to contact you, to give you the most satisfactory solution!']\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUeOBepxn4v_"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for question answering with your model, and pass your text to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UH6VppzLn4v_",
        "outputId": "25dd0f1d-e8c8-478f-f552-5373ee59d1d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.1557905226945877, 'start': 1639, 'end': 1640, 'answer': ']'}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\", model=\"./my_awesome_qa_model/checkpoint-120\")\n",
        "question_answerer(question=question, context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KraYDiifn4v_"
      },
      "source": [
        "You can also manually replicate the results of the `pipeline` if you'd like:\n",
        "\n",
        "Tokenize the text and return PyTorch tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Md6c2wcan4wC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./my_awesome_qa_model/checkpoint-120\")\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxh8akd7n4wC"
      },
      "source": [
        "Pass your inputs to the model and return the `logits`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "0hvfxb1hn4wC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"./my_awesome_qa_model/checkpoint-120\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMKlrd1rn4wC"
      },
      "source": [
        "Get the highest probability from the model output for the start and end positions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "fow1DWKnn4wD"
      },
      "outputs": [],
      "source": [
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgFswfaln4wD"
      },
      "source": [
        "Decode the predicted tokens to get the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "vwgk9WZwn4wD",
        "outputId": "31496730-f67a-4e70-b1ad-766fb61d5bab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'wooden'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "one_for_all",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
