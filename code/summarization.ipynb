{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfecd656-bfa1-4afb-8116-11dce568f75d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Mon Jun  5 09:17:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8    17W / 170W |   6142MiB / 12288MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1217      G   /usr/lib/xorg/Xorg                 59MiB |\n",
      "|    0   N/A  N/A      1702      G   /usr/lib/xorg/Xorg                352MiB |\n",
      "|    0   N/A  N/A      1834      G   /usr/bin/gnome-shell               84MiB |\n",
      "|    0   N/A  N/A   3313266    C+G   ...425343470614401940,262144      243MiB |\n",
      "|    0   N/A  N/A   3436795      G   ...RendererForSitePerProcess       15MiB |\n",
      "|    0   N/A  N/A   3467947      C   ...vs/one_for_all/bin/python     5370MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94726cf9-6559-4006-afd7-b12b00b99350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "src_text = [\n",
    "    '''\n",
    "    About this item\n",
    "HIGH-QUALITY CAST IRON CONSTRUCTION: Built to last of solid cast iron with no welds, weak spots, or seams. Great for training indoor and outdoor. DURABLE VINYL COATED FINISH: Encased with vinyl to prevent corrosion, increase durability, reduce noise, protect flooring and enhance appearance.\n",
    "    '''\n",
    "]\n",
    "\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be621fab-b68f-44bd-a244-a3205ec1e81b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High-QUALITY CAST IRON CONSTRUCTION: Built to last of solid cast iron with no welds, weak spots, or seams.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f17a6fd2-390c-4551-9d7c-5129fedebe7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The aim of this competition is to improve the state-of-the-art in object detection.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "ARTICLE_TO_SUMMARIZE = (\n",
    "'''\n",
    "We present the \"Visual Inductive Priors for Data-Efficient Computer Vision\" challenges. We offer four challenges, where models are to be trained from scratch in a data-deficient setting.\n",
    "\n",
    "This challenge is the VIPriors Object Detection Challenge. The objective of the challenge is to detect bike parts on images from the DelftBikes dataset, containing 10,000 bike images with 22 densely annotated parts for each bike. Besides, we explicitly annotate all part locations and part states as missing, intact, damaged, or occluded. To note that, the dataset contains some noisy labels too, thefore it is more challenging. The evaluation is done on avaliable part, namely intact, damaged and occluded parts.\n",
    "\n",
    "Please note that this challenge does not allow using any pre-trained checkpoint, including any pre-trained backbone! To warrant the competitive integrity of the competition competitive participants may expect a request to share their code with the organizers for a reproducability study.\n",
    "'''\n",
    ")\n",
    "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4f0b2-13e4-4db9-8594-bb0671619826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one_for_all",
   "language": "python",
   "name": "one_for_all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
